# -*- coding: utf-8 -*-
"""hw3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B8fiV7vOQqJc9qxfstlDS5Pn6A4oLb7V
"""

# import our libraries
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

#loading data
D = np.loadtxt('/content/drive/MyDrive/icevelocity.txt')
z = D[:,0]
v = D[:,1]

#quick rmse func
def mean_sq_error(y_true, y_pred):
  """
  LMS 10/08/2024
  mean_sq_error returns the rmse of 2 datasets y values
  inputs: y_true = true values
  y_pred = predicted values
  outputs: rmse = root mean square error
  """
  rmse = np.sqrt(np.nanmean((y_true-y_pred)**2))
  return rmse

coeffs = np.zeros((5,5))
for i in range(5):
    coeffs[i,0:i+1] = np.polyfit(z,v,i)

def polynomfit(A0,A1,A2,A3,A4,x):
  y = np.zeros(len(x))
  for i in range(len(x)):
    y[i] = A0 + A1*x[i] + A2*x[i]**2 + A3*x[i]**3 + A4*x[i]**4
  return y

# Initialize a matrix to store coefficients (degree+1, order columns)
coeffs = np.zeros((5, 5))  # A 5x5 matrix for polynomial fits up to degree 4

# Fill matrix with polynomial coefficients
for i in range(5):

    poly_coeffs = np.polyfit(z, v, i)
    coeffs[i, 0:i+1] = poly_coeffs
    coeffs[i, 0:i+1] = poly_coeffs[::-1]

yplot = np.zeros((len(z),5))

for i in range(5):
  yplot[:,i]=polynomfit(coeffs[i,0],coeffs[i,1],coeffs[i,2],coeffs[i,3],coeffs[i,4],z)

# solving for rmse for each degree polynomial
rms = np.zeros(5)
for i in range(5):
    rms[i] = mean_sq_error(v, yplot[:,i])
rms = np.round(rms,decimals=2)

#plotting
print('1. Plot curves for deg 0 - deg4 along with RMSE values.')
plt.scatter(z,v)
plt.plot(z,yplot[:,0], color='red')
plt.plot(z,yplot[:,1])
plt.plot(z,yplot[:,2])
plt.plot(z,yplot[:,3])
plt.plot(z,yplot[:,4])
plt.xlabel('depth below surface (m)')
plt.ylabel('ice velocity (m/yr)')
plt.legend(['data',('rmse=', rms[0]),('rmse=',rms[1]),('rmse=',rms[2]),('rmse=',rms[3]),('rmse=',rms[4])])

import random

def getTrainTest(data,percenttrain):
      """
      LMS 10/1/2024
      getTrainTest randomly samples percenttrain of data and stores it separately from test percentage of data
      inputs: data = 2-D data set
              percenttrain = % of data desired to train the model
      outputs: traindata = 2-D data set for training a model
               testdata = 2-D data set for testing a model
      """
      dim = np.shape(data)
      ns = dim[0] #number of samples
      nd = dim[1] #number of dimensions
      nsTrain = round(percenttrain*ns)
      Ix = np.arange(ns)
      IxTrain = random.sample(sorted(Ix),nsTrain)
      trainset = data[IxTrain,:]
      IxTest = [1]*len(Ix)
      for i in range(len(IxTrain)):
            IxTest[IxTrain[i]]=0
      IxTest = np.where(IxTest)[0]
      testset = data[IxTest,:]
      return trainset,testset

#initializing arrays to store train and test data
ztest = np.zeros((9,1000))
vtest = np.zeros((9,1000))
ztrain = np.zeros((82,1000))
vtrain = np.zeros((82,1000))

#using gettraintest to get 1000 sets of train and test data
for i in range(1000):
  testtrain = getTrainTest(D,0.9)
  train = testtrain[0]
  test = testtrain[1]
  ztrain[:,i] = train[:,0]
  vtrain[:,i] = train[:,1]
  ztest[:,i] = test[:,0]
  vtest[:,i] = test[:,1]
  testtrain = 0
  train = 0
  test = 0

#initializing arrays to store polyfit coefficients for each degree and 1000 tests
deg0 = np.zeros((1,1000))
deg1 = np.zeros((2,1000))
deg2 = np.zeros((3,1000))
deg3 = np.zeros((4,1000))
deg4 = np.zeros((5,1000))

#generating polyfit coefficients for degrees 0-4 for 1000 sets of train data
for i in range(1000):
    deg0[0,i] = np.polyfit(ztrain[:,i],vtrain[:,i],0)
    deg1[:,i] = np.polyfit(ztrain[:,i],vtrain[:,i],1)
    deg2[:,i] = np.polyfit(ztrain[:,i],vtrain[:,i],2)
    deg3[:,i] = np.polyfit(ztrain[:,i],vtrain[:,i],3)
    deg4[:,i] = np.polyfit(ztrain[:,i],vtrain[:,i],4)

#initalizing arrays to store mean and SD of each coefficient
statdeg0 = np.zeros((2,1))
statdeg1 = np.zeros((2,2))
statdeg2 = np.zeros((2,3))
statdeg3 = np.zeros((2,4))
statdeg4 = np.zeros((2,5))

#solving for mean and SD of each coefficient
statdeg0[0,0] = np.mean(deg0)
statdeg0[1,0] = np.std(deg0)

for i in range(2):
  statdeg1[0,i] = np.mean(deg1[i,:])
  statdeg1[1,i] = np.std(deg1[i,:])

for i in range(3):
  statdeg2[0,i] = np.mean(deg2[i,:])
  statdeg2[1,i] = np.std(deg2[i,:])

for i in range(4):
  statdeg3[0,i] = np.mean(deg3[i,:])
  statdeg3[1,i] = np.std(deg3[i,:])

for i in range(5):
  statdeg4[0,i] = np.mean(deg4[i,:])
  statdeg4[1,i] = np.std(deg4[i,:])

import pandas as pd
#displaying data in data frame
meandata = {
    '': ['A0', 'A1', 'A2','A3','A4'],
    '0th': [statdeg0[0,0], 'NA', 'NA','NA','NA'],
    '1st': [statdeg1[0,1], statdeg1[0,0], 'NA','NA','NA'],
    '2nd': [statdeg2[0,2], statdeg2[0,1], statdeg2[0,0],'NA','NA'],
    '3rd': [statdeg3[0,3], statdeg3[0,2], statdeg3[0,1],statdeg3[0,0],'NA'],
    '4th': [statdeg4[0,4], statdeg4[0,3], statdeg4[0,2],statdeg4[0,1],statdeg4[0,0]]
}

meandf = pd.DataFrame(meandata)
print('2. Report the model parameters in a table, using the mean and standard deviation of the 1000 parameter estimates.')
print('mean value data table')
print(meandf)

stddata = {
    '': ['A0', 'A1', 'A2','A3','A4'],
    '0th': [statdeg0[1,0], 'NA', 'NA','NA','NA'],
    '1st': [statdeg1[1,1], statdeg1[1,0], 'NA','NA','NA'],
    '2nd': [statdeg2[1,2], statdeg2[1,1], statdeg2[1,0],'NA','NA'],
    '3rd': [statdeg3[1,3], statdeg3[1,2], statdeg3[1,1],statdeg3[1,0],'NA'],
    '4th': [statdeg4[1,4], statdeg4[1,3], statdeg4[1,2],statdeg4[1,1],statdeg4[1,0]]
}

stddf = pd.DataFrame(stddata)
print('standard deviation data table')
print(stddf)

rmse_90 = np.zeros((5,1000))

#storing rmses for each trial of each degree by using polyfit coefficients to make a vmodel to compare with vtest
for n in range(5):
    for i in range(1000):
      if n==0:
          vmodel = np.zeros(len(ztest[:,0]))
          vmodel = polynomfit(deg0[0,i],0,0,0,0,ztest[:,i])
          rmse_90[0,i] = mean_sq_error(vtest[:,i], vmodel)
      elif n==1:
          vmodel = np.zeros(len(ztest[:,0]))
          vmodel = polynomfit(deg1[1,i],deg1[0,i],0,0,0,ztest[:,i])
          rmse_90[1,i] = mean_sq_error(vtest[:,i], vmodel)
      elif n==2:
          vmodel = np.zeros(len(ztest[:,0]))
          vmodel = polynomfit(deg2[2,i],deg2[1,i],deg2[0,i],0,0,ztest[:,i])
          rmse_90[2,i] = mean_sq_error(vtest[:,i], vmodel)
      elif n==3:
          vmodel = np.zeros(len(ztest[:,0]))
          vmodel = polynomfit(deg3[3,i],deg3[2,i],deg3[1,i],deg3[0,i],0,ztest[:,i])
          rmse_90[3,i] = mean_sq_error(vtest[:,i], vmodel)
      elif n==4:
          vmodel = np.zeros(len(ztest[:,0]))
          vmodel = polynomfit(deg4[4,i],deg4[3,i],deg4[2,i],deg4[1,i],deg4[0,i],ztest[:,i])
          rmse_90[4,i] = mean_sq_error(vtest[:,i], vmodel)

#plotting 5 histograms to compare rmse for each degree polynomial
print('3. Plot the distribution of RMSE values for each degree polynomial.')
plt.figure(figsize=(6,7))
plt.subplot(5,1,1)
plt.hist(rmse_90[0,:])
plt.xlim([0, 10])
plt.title('rmse for degree 0')
plt.subplot(5,1,2)
plt.hist(rmse_90[1,:])
plt.xlim([0, 10])
plt.title('rmse for degree 1')
plt.subplot(5,1,3)
plt.hist(rmse_90[2,:])
plt.xlim([0, 9])
plt.title('rmse for degree 2')
plt.subplot(5,1,4)
plt.hist(rmse_90[3,:])
plt.xlim([0, 10])
plt.title('rmse for degree 3')
plt.subplot(5,1,5)
plt.hist(rmse_90[4,:])
plt.xlim([0, 10])
plt.title('rmse for degree 4')
plt.tight_layout()
plt.show()

def moving_window(x,y,windowsize,xeval):
  """
  LMS 10/07/2024
  moving_window is a function to create a moving window average of input x and y data, evaluated over a separate x array
  inputs: x = x values of data set
          y = y values of data set
          xeval = x values to evaluate moving window average
          windowsize = size of window
  outputs: ymove = moving window average of y
  """
  ymove = np.zeros(len(xeval))
  for i in range(len(xeval)):
    xmovehigh = xeval[i] + windowsize/2
    xmovelow = xeval[i] - windowsize/2
    Ix = np.logical_and(x<xmovehigh,x>xmovelow)
    yrange = y[Ix]
    ymove[i] = np.mean(yrange)
  return ymove

#creating arrays to plot MWA of window size 3, 10, and 50
x_eval = np.linspace(0,180,181)
window_3 = moving_window(z,v,3,x_eval)
window_10 = moving_window(z,v,10,x_eval)
window_50 = moving_window(z,v,50,x_eval)

#plotting MWA
print('4. Use a moving window average to estimate the velocity as a function of depth, and plot with the data for a window size of 3,10, and 50 meters.')
plt.figure(figsize=(6,7))
plt.subplot(3,1,1)
plt.plot(x_eval,window_3,color='red')
plt.scatter(z,v)
plt.ylabel('velocity (m/yr)')
plt.xlabel('depth (m)')
plt.title('3m moving window')
plt.legend(['moving window','raw data'])
plt.subplot(3,1,2)
plt.plot(x_eval,window_10,color='red')
plt.scatter(z,v)
plt.ylabel('velocity (m/yr)')
plt.xlabel('depth (m)')
plt.title('10m moving window')
plt.legend(['moving window','raw data'])
plt.subplot(3,1,3)
plt.plot(x_eval,window_50,color='red')
plt.scatter(z,v)
plt.ylabel('velocity (m/yr)')
plt.xlabel('depth (m)')
plt.title('50m moving window')
plt.legend(['moving window','raw data'])
plt.tight_layout()
plt.show

def weighted_moving_window(x,y,windowsize,xeval):
  """
  LMS 10/07/2024
  weighted_moving_window is a function to create a weighted window moving average
  of input x and y data, evaluated over a separate x array
  inputs: x = x values of data set
          y = y values of data set
          xeval = x values to evaluate
          windowsize = size of window
  outputs: ymove = moving window average of y
  """
  ymove = np.zeros(len(xeval))
  for i in range(len(xeval)):
      xmovehigh = xeval[i] + windowsize/2
      xmovelow = xeval[i] - windowsize/2
      Ix = np.logical_and(x<xmovehigh,x>xmovelow)
      yrange = y[Ix]
      xrange = x[Ix]
      w = np.zeros(len(yrange))
      for n in range(len(yrange)):
          w[n] = (15/16)*(1-((xrange[n]-xeval[i])/(windowsize/2))**2)**2
      ymove[i] = np.dot(w,yrange)/np.sum(w)
  return ymove

#plotting arrays for  WMWA
xspace = np.linspace(0,180,360)
weighted_3 = weighted_moving_window(z,v,3,xspace)
weighted_10 = weighted_moving_window(z,v,10,xspace)
weighted_50 = weighted_moving_window(z,v,50,xspace)

#plotting WMWA
print('5. Repeat, using a weighted moving window average (non-parametric smooth), for a window size of 3,10, and 50 meters.')
plt.figure(figsize=(6,7))
plt.subplot(3,1,1)
plt.plot(xspace,weighted_3,color='red')
plt.scatter(z,v)
plt.ylabel('velocity (m/yr)')
plt.xlabel('depth (m)')
plt.title('3m weighted moving window')
plt.legend(['moving window','raw data'])
plt.subplot(3,1,2)
plt.plot(xspace,weighted_10,color='red')
plt.scatter(z,v)
plt.ylabel('velocity (m/yr)')
plt.xlabel('depth (m)')
plt.title('10m weighted moving window')
plt.legend(['moving window','raw data'])
plt.subplot(3,1,3)
plt.plot(xspace,weighted_50,color='red')
plt.scatter(z,v)
plt.ylabel('velocity (m/yr)')
plt.xlabel('depth (m)')
plt.title('50m weighted moving window')
plt.legend(['moving window','raw data'])
plt.tight_layout()
plt.show

#creating array of dif window sizes to test
windowoptions = np.linspace(3,80,78)
#initializing array to store rmse for each window size and each test
rmse_weighted = np.zeros((len(windowoptions),1000))
#solving for rmse of each WMWA window size aginst test sets
for i in range(1000):
  for n in range(len(windowoptions)):
    eval = weighted_moving_window(ztrain[:,i],vtrain[:,i],windowoptions[n],ztest[:,i])
    rmse_weighted[n,i] = mean_sq_error(eval, vtest[:,i])

mean_rmse=np.zeros(len(windowoptions))
#getting mean rmse for each window size
for i in range(len(windowoptions)):
  mean_rmse[i] = np.nanmean(rmse_weighted[i,:])

#plotting mean window size
print('6. Find the optimum window size for the weighted moving window average model.')
plt.scatter(windowoptions,mean_rmse)
plt.xlabel('window size (m)')
plt.ylabel('rmse')
bestwindowsize = windowoptions[np.where(mean_rmse==np.nanmin(mean_rmse))]
print(f'Best window size is {bestwindowsize}')

import math

# Constants
uxsurf = v[0]  # Surface velocity (first element of v)
rho = 917      # Density of ice (kg/m^3)
g = 9.81       # Gravity (m/s^2)
theta = 10     # Angle (degrees)

# Parameter ranges
A_ice = np.linspace(1e-18, 1e-17, 1000)  # A_grad range
n_ice = np.linspace(2, 4, 1000)      # n_grad range

# Initialize RMSE array
rmse_ice = np.zeros((len(A_ice), len(n_ice)))

# Calculate RMSE for each combination of A and n
for i in range(len(A_ice)):
    for j in range(len(n_ice)):
        umodel = uxsurf - (A_ice[i] * (rho * g * np.sin(np.radians(theta)))**n_ice[j]) * z**(n_ice[j] + 1)
        rmse_ice[i, j] = np.sqrt(np.mean((umodel - v)**2))  # Calculate RMSE

# Find the indices of the minimum RMSE
minrmse = np.unravel_index(np.argmin(rmse_ice), rmse_ice.shape)
best_A = A_ice[minrmse[0]]
best_n = n_ice[minrmse[1]]
minimum_rmse = np.min(rmse_ice)

# Print results
print('7. Using the measured velocity at a depth of z = 0 m for the surface velocity, ux,surf , find the optimum values for the flow law parameters A and n, using the grid search (brute-force) method.')
print(f'Best A: {best_A:.6e}, Best n: {best_n:.6f}')
print(f'Minimum RMSE: {minimum_rmse:.6f}')

# now plot as heatmap
print('8. Plot the root mean square (RMS) error (mean over all depths) as a function of A and n.')
plt.figure(1)
plt.clf()
plt.imshow(rmse_ice,extent=[2.5, 3.5, min(A_ice), max(A_ice)], aspect='auto',origin='lower',cmap='viridis',vmin=0, vmax=10)
plt.xlabel('n')
plt.ylabel('A')
plt.colorbar(label='RMSE')
plt.title('RMSE values for linear model')
plt.scatter(best_n,best_A,25,'red',label='bruteforce')
plt.show()

A_ice = np.linspace(1e-18, 1e-17, 1000)
rmseee_ice=np.zeros(len(A_ice))
for i in range(len(A_ice)):
      umodel = uxsurf - (A_ice[i] * (rho * g * np.sin(np.radians(theta)))**3) * z**(3 + 1)
      rmseee_ice[i] = np.sqrt(np.mean((umodel - v)**2))  # Calculate RMS


plt.plot(A_ice,rmseee_ice)
plt.ylabel('rmse')
plt.xlabel('A')

# lets do gradient descent
from scipy.optimize import minimize

# Initialize a list to store RMSE values
rmse_history = []

def RMSEval(params):
    const = params  # A*rho*g*sin(theta)^n
    # Compute the modeled velocity (u_model) based on the current A_grad and n_grad
    umodel = uxsurf - const * z**(3 + 1)
    # Calculate RMSE between the modeled velocity and the observed velocity (v)
    rmse = np.sqrt(np.mean((umodel - v)**2))
    rmse_history.append(rmse)
    return rmse

# Perform optimization
initial_guess = [2e-8]  # Starting guess for A_grad and n_grad
result = minimize(RMSEval, initial_guess)

# Extract the best-fit parameters from the optimization result
pbest = result.x
best_const = pbest[0]
divider = (rho*g*np.sin(np.radians(theta)))**3
A_best = best_const/divider
print('9. Find the optimum values of A and n using the gradient search method with MATLAB’s fminsearch function.')
print(f'Best parameters: A_grad = {A_best:.6e}')

#including relative density histo function
def rdh(data,bins):
    """
    LMS 9/3/24
    relative density histogram function
    inputs: data = 1-D dataset array
    outputs: rdh = plot of relative density histogram
    """
    plt.figure(2)
    nc, xbins = np.histogram(data, bins=bins)
    dx = xbins[1] - xbins[0]  # bin width
    rdh = nc / (sum(nc) * dx)  # relative density histogram
    plt.bar(xbins[:-1] + dx / 2, rdh, width=dx, edgecolor='black')
    return rdh

def relative_density_histogram(data, bins=30):
    """
    LMS 9/3/24
    relative density histogram function
    inputs: data = 1-D dataset array
    outputs: rdh = plot of relative density histogram
    """
    plt.figure(2)
    nc, xbins = np.histogram(data, bins=bins)
    dx = xbins[1] - xbins[0]  # bin width
    rdh = nc / (sum(nc) * dx)  # relative density histogram
    plt.bar(xbins[:-1] + dx / 2, rdh, width=dx, edgecolor='black')
    return rdh

# Define the RMSE evaluation function for optimization
def RMSEval(params, z, v, uxsurf, rho, g, theta):
    const = params
    umodel = uxsurf - const* z**(3 + 1)
    rmse = np.sqrt(np.mean((umodel - v) ** 2))  # calculate RMSE
    return rmse

# Main function to perform optimization
def perform_optimization(data, percenttrain=0.9, num_iterations=1000):
    rmse_results = []
    A_val = []
    for i in range(num_iterations):
        # Get training and testing data
        trainset, testset = getTrainTest(data, percenttrain)

        # Extract z and v from training data
        z_train = trainset[:, 0]
        v_train = trainset[:, 1]

        # Initialize constants
        uxsurf = v[0]
        rho = 917
        g = 9.81
        theta = 10

        # Starting guess for A_grad
        initial_guess = [2e-8]

        # Perform optimization
        result = minimize(RMSEval, initial_guess, args=(z_train, v_train, uxsurf, rho, g, theta))

        # Extract the best-fit parameters
        best_const = result.x[0]
        divider = (rho * g * np.sin(np.radians(theta))) ** 3
        A_bbest = best_const / divider

        # Store the final RMSE for this iteration
        rmse_results.append(result.fun)  # Store the final RMSE for this iteration
        A_val.append(A_bbest)
    return rmse_results, A_val


# Run the optimization
rmse_results = perform_optimization(D, percenttrain=0.9, num_iterations=1000)[0]
A_val = perform_optimization(D, percenttrain=0.9, num_iterations=1000)[1]

print('10.Randomly sample 90% of the dataset and find the optimum value of A using the gradient search method, and repeat 1000 times. Plot the distribution of A and the RMS error (over all depths) in the model using a relative density histogram.')

rmseplot = np.zeros(len(A_val))
for i in range(len(A_val)):
   umodel = uxsurf - (A_val[i] * (rho * g * np.sin(np.radians(theta)))**3) * z**(3 + 1)
   rmseplot[i] = np.sqrt(np.mean((umodel - v)**2))

rdh(rmseplot, bins=30)
plt.title('relative density histogram of RMSE Results')
plt.xlabel('RMSE')
plt.ylabel('relative density')
plt.show()


rdh(A_val, bins=30)
plt.title('relative density histogram of A Results')
plt.xlabel('A')
plt.ylabel('relative density')
plt.show()

mean_A = np.mean(A_val)
std_A = np.std(A_val)

plt.figure(1)
plt.clf()
plt.imshow(rmse_ice,extent=[2.5, 3.5, 4e-18, max(A_ice)], aspect='auto',origin='lower',cmap='viridis',vmin=0, vmax=10)
plt.xlabel('n')
plt.ylabel('A')
plt.colorbar(label='RMSE')
plt.title('RMSE values for linear model')
plt.scatter(best_n,best_A,25,'red',label='bruteforce')
plt.errorbar(3, mean_A, yerr=std_A, fmt='o', color='red', label='Mean A with Std Dev', markersize=2)  # Note the xerr for A
plt.xlabel('n')
plt.ylabel('A')
plt.legend()
plt.show()

# Print statistics of the best A values
print(f'Mean A: {mean_A}, Std Dev A: {std_A}')

rmse_mean = np.mean(rmse_results)
rmse_std = np.std(rmse_results)
print('12. For each of A and model RMS error, use the normal distribution model to generate 1000 simulated values with the mean and standard deviations from your Monte-Carlo simulations.')
A_dist = np.random.normal(mean_A, std_A, 1000)
rmse_dist = np.random.normal(rmse_mean, rmse_std, 1000)

stat_A, p_A = stats.ks_2samp(A_dist, A_val)
stat_RMSE, p_RMSE = stats.ks_2samp(rmse_dist, rmse_results)

print('13. Use MATLAB’s kstest2 function to compare the actual distributions from your Monte-carlo parameter fitting (#9), with those simulated assuming a normal distribution (#11).')
print(f'KS p-value for A: {p_A}')
print(f'KS p-value for RMSE: {p_RMSE}')